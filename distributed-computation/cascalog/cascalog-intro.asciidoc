=== Introduction to Cascalog

The next several recipes deal with Cascalog, a library that makes it
easy to run Clojure on Hadoop. Cascalog defines a DSL based on
Datalog, the same query language that backs Datomic. It might be a
strange at first, but you will be thinking in Datalog in no time. Once
you've wet your feet with these recipes visit the 
https://github.com/nathanmarz/cascalog/wiki[Cascalog wiki] for more
information on writing your own queries.

Cascalog provides a concise syntax for describing data processing
jobs. Transformations and aggregates are easy to express in
Cascalog. Joins are particularly simple. You might like the Cascalog
syntax so much that you use it even for local jobs.

You can run your Cascalog jobs in a number of different ways. The
easiest way is to run jobs locally. When running jobs locally Cascalog
uses Hadoop's local mode, completing entire job on your own
computer. You get the benefit of parallelism, without the hassle of
setting up a cluster. 

Once your jobs outgrow local mode, you'll need to start running them
on a Hadoop cluster. Having your own cluster is a lot of fun, but it
can be a fair amount of work (and money!) to setup and maintain. If
you don't need a cluster very often, you might consider running your
job on Amazon EMR, Elastic MapReduce. EMR provides on-demand Hadoop
clusters the same way EC2 provides on-demand servers. You'll need an
Amazon Web Services account to run the job, but it isn't difficult.
You can read exactly how to do it later in <<sec_cascalog_emr>>.
Whether you run your job on EMR or on your own cluster, you will
package up your code into an uberjar, then send it to Hadoop for
execution. It is surprisingly simple to get hundreds of computers
working on your task.
