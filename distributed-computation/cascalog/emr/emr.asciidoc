[[sec_cascalog_emr]]
=== Running a Cascalog Job On Elastic MapReduce
[role="byline"]
by Alex Robbins

// TODO: This example needs a cloneable project to play along with
// input/output data.

==== Problem

You have a large amount of data to process, but you don't have a
Hadoop cluster.

==== Solution

Amazon's Elastic MapReduce (EMR) provides on-demand Hadoop clusters.
You'll need an Amazon Web Services account to use EMR. Create an
account at _aws.amazon.com_.

First, write a Cascalog job as you normally would. There are a number
of recipes in this chapter that can help you create a complete
Cascalog job. TODO is a great example.

Once you have a Cascalog project, package it into an uberjar.

[source,terminal]
----
$ lein uberjar
----

Next, upload the generated jar (named something like
`target/<project-name>-<version>-standalone.jar`) to S3. If you
haven't ever uploaded a file to S3 follow the S3 documentation to
http://docs.aws.amazon.com/AmazonS3/latest/gsg/CreatingABucket.html[Create
a Bucket] and
http://docs.aws.amazon.com/AmazonS3/latest/gsg/PuttingAnObjectInABucket.html[Adding
an Object to a Bucket]. Repeat this process to upload your input data.
Take note of the path of jar and input data location.

To create your MapReduce job visit
_https://console.aws.amazon.com/elasticmapreduce/_ and select "Create
New Job Flow." Once you're in the new job flow wizard choose the
"Custom JAR" job type.

// TODO: Specify an actual example.

Select "Continue" and proceed to enter in your JAR's location and
arguments. "JAR Location" is the S3 path you noted from earlier. "JAR
Arguments are all of the arguments you would normally pass when
executing your jar. First, pass the fully qualified name of the class
you want to execute. +clojurebook.cascalog.emr.Main+ for example. Then
pass any arguments your job expects. For example, you probably need at
least an input and output argument. Note that in an EMR job you'll be
reading from and writing so S3.

After your job has run, you should be able to retrieve the results
from S3. Elastic MapReduce also allows you to setup a logging path to
help with debugging if your job doesn't complete like you expect.

==== Discussion

Amazon's EMR is a great solution if you have big Cascalog jobs, but
you don't have them very often. Maintaining your own Hadoop cluster
can be a fair amount of time and money. If you can keep the cluster
busy, it is a great investment. If you only need it a couple times a
month, you might be better off using EMR for on-demand Hadoop
clusters.

==== See Also

* <<sec_cascalog_etl>>
